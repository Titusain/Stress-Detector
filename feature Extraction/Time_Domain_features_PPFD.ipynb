{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCuQ9xu5UbOW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fftpack import fft\n",
        "import seaborn as sns\n",
        "from scipy.signal import welch\n",
        "from scipy import signal as sig\n",
        "from scipy.integrate import simps\n",
        "from numpy.fft import fft, ifft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "BOCdq84LUhDo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16158503-cc61-4d90-8172-693429f38ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def arithematic_features(s):\n",
        "    arr = []\n",
        "    for i in range(1, 32):\n",
        "        channel = np.asarray(s.iloc[i:i+1, 1:])\n",
        "        channel = channel.reshape(-1)\n",
        "        for j in range(0, 25):\n",
        "            window = channel[j*128:(j+1)*128]\n",
        "            features = np.empty((1, 10))\n",
        "            features[0, 0] = np.mean(window)\n",
        "            features[0, 1] = np.var(window)\n",
        "            features[0, 2] = np.std(window)\n",
        "\n",
        "            features[0, 3] = np.min(window)\n",
        "            features[0, 4] = np.max(window)\n",
        "            features[0, 5] = features[0, 4] - features[0, 3]\n",
        "            features[0, 6] = np.median(window)\n",
        "            data = window\n",
        "            var = np.var(data)\n",
        "            features[0, 7] = var\n",
        "            data_1 = np.diff(data)\n",
        "            data_2 = np.diff(data_1)\n",
        "            hj_mb = np.sqrt(np.var(data_1) / var)\n",
        "            hj_comp = (np.sqrt(np.var(data_2) / np.var(data_1))) / hj_mb\n",
        "            features[0, 8] = hj_mb\n",
        "            features[0, 9] = hj_comp\n",
        "            arr.append(features)\n",
        "    channel = np.asarray(s.iloc[31:, 1:])\n",
        "    channel = channel.reshape(-1)\n",
        "    for j in range(0, 25):\n",
        "        window = channel[j*128:(j+1)*128]\n",
        "        features = np.empty((1, 10))\n",
        "        features[0, 0] = np.mean(window)\n",
        "        features[0, 1] = np.var(window)\n",
        "        features[0, 2] = np.std(window)\n",
        "        features[0, 3] = np.min(window)\n",
        "        features[0, 4] = np.max(window)\n",
        "        features[0, 5] = features[0, 4] - features[0, 3]\n",
        "        features[0, 6] = np.median(window)\n",
        "        data = window\n",
        "        var = np.var(data)\n",
        "        features[0, 7] = var\n",
        "        data_1 = np.diff(data)\n",
        "        data_2 = np.diff(data_1)\n",
        "        hj_mb = np.sqrt(np.var(data_1) / var)\n",
        "        hj_comp = (np.sqrt(np.var(data_2) / np.var(data_1))) / hj_mb\n",
        "        features[0, 8] = hj_mb\n",
        "        features[0, 9] = hj_comp\n",
        "        arr.append(features)\n",
        "    return np.concatenate(arr, axis=0)\n"
      ],
      "metadata": {
        "id": "ElYb7307a4bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reset(arr):\n",
        "  ans=[]\n",
        "  for i in range(25):\n",
        "    temp=[]\n",
        "    for j in range(32):\n",
        "      for z in range(10):\n",
        "        # print(j*25+i)\n",
        "        temp.append(arr[j*25+i][z])\n",
        "    ans.append(temp)\n",
        "  return ans"
      ],
      "metadata": {
        "id": "cNyyD6z_KTpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naming(featureList,CHANNELS):\n",
        "  ans=[]\n",
        "  for i in range(32):\n",
        "    for j in range (10):\n",
        "      str=CHANNELS[i]+'.'+featureList[j]\n",
        "      ans.append(str)\n",
        "  return ans"
      ],
      "metadata": {
        "id": "6d7cP2COKUWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_files=os.listdir(\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Arithmetic_task\")\n",
        "for your_file_name in list_of_files:\n",
        "  data_path=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Arithmetic_task/\" + your_file_name\n",
        "  df = pd.read_csv(data_path)\n",
        "  df=df.drop(['Unnamed: 0'], axis=1)\n",
        "  df=df.T\n",
        "  s=pd.DataFrame(df)\n",
        "  arr=arithematic_features(s)\n",
        "  ans=np.array(arr)\n",
        "  ans=reset(ans)\n",
        "  featureList = ['mean_value','variance_value','std_value','min_value','max_value','peak_to_peak_value','median','var','hj_mobility','hj_complexity']\n",
        "  CHANNELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"]\n",
        "  headerList = naming(featureList,CHANNELS)\n",
        "  size = len(your_file_name)\n",
        "  new_name = your_file_name[:size - 4]\n",
        "  s=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data_features/Time_domain_features/Arithmetic_task/\"+new_name+\".csv\"\n",
        "  DF = pd.DataFrame(ans)\n",
        "  # file.to_csv(\"gfg2.csv\", header=headerList, index=False)\n",
        "  DF.to_csv(s,header=headerList)"
      ],
      "metadata": {
        "id": "ch97z-UTcdZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_files=os.listdir(\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Mirror_image_task\")\n",
        "for your_file_name in list_of_files:\n",
        "  data_path=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Mirror_image_task/\" + your_file_name\n",
        "  df = pd.read_csv(data_path)\n",
        "  df=df.drop(['Unnamed: 0'], axis=1)\n",
        "  df=df.T\n",
        "  s=pd.DataFrame(df)\n",
        "  arr=arithematic_features(s)\n",
        "  ans=np.array(arr)\n",
        "  ans=reset(ans)\n",
        "  featureList = ['mean_value','variance_value','std_value','min_value','max_value','peak_to_peak_value','median','var','hj_mobility','hj_complexity']\n",
        "  CHANNELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"]\n",
        "  headerList = naming(featureList,CHANNELS)\n",
        "  size = len(your_file_name)\n",
        "  new_name = your_file_name[:size - 4]\n",
        "  s=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data_features/Time_domain_features/Mirror_image_task/\"+new_name+\".csv\"\n",
        "  DF = pd.DataFrame(ans)\n",
        "  # file.to_csv(\"gfg2.csv\", header=headerList, index=False)\n",
        "  DF.to_csv(s,header=headerList)"
      ],
      "metadata": {
        "id": "Ji16t6VBKNFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_files=os.listdir(\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Stroop_task\")\n",
        "for your_file_name in list_of_files:\n",
        "  data_path=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Stroop_task/\" + your_file_name\n",
        "  df = pd.read_csv(data_path)\n",
        "  df=df.drop(['Unnamed: 0'], axis=1)\n",
        "  df=df.T\n",
        "  s=pd.DataFrame(df)\n",
        "  arr=arithematic_features(s)\n",
        "  ans=np.array(arr)\n",
        "  ans=reset(ans)\n",
        "  featureList = ['mean_value','variance_value','std_value','min_value','max_value','peak_to_peak_value','median','var','hj_mobility','hj_complexity']\n",
        "  CHANNELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"]\n",
        "  headerList = naming(featureList,CHANNELS)\n",
        "  size = len(your_file_name)\n",
        "  new_name = your_file_name[:size - 4]\n",
        "  s=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data_features/Time_domain_features/Stroop_task/\"+new_name+\".csv\"\n",
        "  DF = pd.DataFrame(ans)\n",
        "  # file.to_csv(\"gfg2.csv\", header=headerList, index=False)\n",
        "  DF.to_csv(s,header=headerList)"
      ],
      "metadata": {
        "id": "pFMnqnt-Kmpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_files=os.listdir(\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Relax\")\n",
        "for your_file_name in list_of_files:\n",
        "  data_path=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data/Relax/\" + your_file_name\n",
        "  df = pd.read_csv(data_path)\n",
        "  df=df.drop(['Unnamed: 0'], axis=1)\n",
        "  df=df.T\n",
        "  s=pd.DataFrame(df)\n",
        "  arr=arithematic_features(s)\n",
        "  ans=np.array(arr)\n",
        "  ans=reset(ans)\n",
        "  featureList = ['mean_value','variance_value','std_value','min_value','max_value','peak_to_peak_value','median','var','hj_mobility','hj_complexity']\n",
        "  CHANNELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\"]\n",
        "  headerList = naming(featureList,CHANNELS)\n",
        "  size = len(your_file_name)\n",
        "  new_name = your_file_name[:size - 4]\n",
        "  s=\"/content/drive/MyDrive/SAM40/Preprocessing_own/Preprocessed_filtered_data_features/Time_domain_features/Relax/\"+new_name+\".csv\"\n",
        "  DF = pd.DataFrame(ans)\n",
        "  # file.to_csv(\"gfg2.csv\", header=headerList, index=False)\n",
        "  DF.to_csv(s,header=headerList)"
      ],
      "metadata": {
        "id": "RgPh5GOHKyfN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}